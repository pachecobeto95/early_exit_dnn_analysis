{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp_prob_inference_edge_calib_mbdi_full.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b337975c22d46579a5437292bd555fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_323977f630cd4fcf8f80a76014a52b93",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_657740fc04744fa2a0ac2ea2615727ae",
              "IPY_MODEL_a3b67458b23045c9ae0d31faff11db75",
              "IPY_MODEL_364679377ef64df79bc9164ba5f11e52"
            ]
          }
        },
        "323977f630cd4fcf8f80a76014a52b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "657740fc04744fa2a0ac2ea2615727ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_735167791ec24ad7a615e3777c9b78c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc6957591b6b478dbdae70b41a312f10"
          }
        },
        "a3b67458b23045c9ae0d31faff11db75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09fb1763e1f5443885896fcbabd48a61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14212972,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14212972,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f29a754b0be2492090dd57e738bf754c"
          }
        },
        "364679377ef64df79bc9164ba5f11e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74a16c448db24c0498db4aafb8a8c853",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13.6M/13.6M [00:00&lt;00:00, 39.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_850dc6e051ec41d8868b50ac6768baf1"
          }
        },
        "735167791ec24ad7a615e3777c9b78c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc6957591b6b478dbdae70b41a312f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09fb1763e1f5443885896fcbabd48a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f29a754b0be2492090dd57e738bf754c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74a16c448db24c0498db4aafb8a8c853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "850dc6e051ec41d8868b50ac6768baf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Eb43EmL_TD0",
        "outputId": "0b0422ec-5a8f-4057-ad1f-dee4d1c7e627"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision.utils import save_image\n",
        "import os, cv2, sys, time, math, os\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, WeightedRandomSampler\n",
        "from torch.utils.data import random_split\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from itertools import product\n",
        "import pandas as pd\n",
        "import torchvision.models as models\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, transforms\n",
        "!pip install pthflops\n",
        "from pthflops import count_ops\n",
        "from pthflops import count_ops\n",
        "from torch import Tensor\n",
        "from typing import Callable, Any, Optional, List\n",
        "import functools\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pthflops\n",
            "  Downloading pthflops-0.4.1.tar.gz (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pthflops) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pthflops) (3.7.4.3)\n",
            "Building wheels for collected packages: pthflops\n",
            "  Building wheel for pthflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pthflops: filename=pthflops-0.4.1-py3-none-any.whl size=10063 sha256=c0f42b200823f82e5d15f0ae46d2d779ecb146e143ac5f094ad952e2a575c793\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/41/05/475bdaebaaf3a44f25367a8dc0ac9d4b8edbb7f5fa19724c70\n",
            "Successfully built pthflops\n",
            "Installing collected packages: pthflops\n",
            "Successfully installed pthflops-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev0s8J_eAFw6"
      },
      "source": [
        "class LoadDataset():\n",
        "  def __init__(self, input_dim, batch_size_train, batch_size_test, save_idx, model_id, seed=42):\n",
        "    self.input_dim = input_dim\n",
        "    self.batch_size_train = batch_size_train\n",
        "    self.batch_size_test = batch_size_test\n",
        "    self.seed = seed\n",
        "    self.save_idx = save_idx\n",
        "    self.model_id = model_id\n",
        "\n",
        "    #To normalize the input images data.\n",
        "    mean = [0.457342265910642, 0.4387686270106377, 0.4073427106250871]\n",
        "    std = [0.26753769276329037, 0.2638145880487105, 0.2776826934044154]\n",
        "\n",
        "    # Note that we apply data augmentation in the training dataset.\n",
        "    self.transformations_train = transforms.Compose([transforms.Resize((input_dim, input_dim)),\n",
        "                                                     transforms.RandomChoice([\n",
        "                                                                              transforms.ColorJitter(brightness=(0.80, 1.20)),\n",
        "                                                                              transforms.RandomGrayscale(p = 0.25)]),\n",
        "                                                     transforms.RandomHorizontalFlip(p = 0.25),\n",
        "                                                     transforms.RandomRotation(25),\n",
        "                                                     transforms.ToTensor(), \n",
        "                                                     transforms.Normalize(mean = mean, std = std),\n",
        "                                                     ])\n",
        "\n",
        "    # Note that we do not apply data augmentation in the test dataset.\n",
        "    self.transformations_test = transforms.Compose([\n",
        "                                                     transforms.Resize(input_dim), \n",
        "                                                     transforms.ToTensor(), \n",
        "                                                     transforms.Normalize(mean = mean, std = std),\n",
        "                                                     ])\n",
        "\n",
        "  def cifar_10(self, root_path, split_ratio):\n",
        "    # This method loads Cifar-10 dataset. \n",
        "    \n",
        "    # saves the seed\n",
        "    torch.manual_seed(self.seed)\n",
        "\n",
        "    # This downloads the training and test CIFAR-10 datasets and also applies transformation  in the data.\n",
        "    train_set = datasets.CIFAR10(root=root_path, train=True, download=True, transform=self.transformations_train)\n",
        "    test_set = datasets.CIFAR10(root=root_path, train=False, download=True, transform=self.transformations_test)\n",
        "\n",
        "    classes_list = train_set.classes\n",
        "\n",
        "    # This line defines the size of validation dataset.\n",
        "    val_size = int(split_ratio*len(train_set))\n",
        "\n",
        "    # This line defines the size of training dataset.\n",
        "    train_size = int(len(train_set) - val_size)\n",
        "\n",
        "    #This line splits the training dataset into train and validation, according split ratio provided as input.\n",
        "    train_dataset, val_dataset = random_split(train_set, [train_size, val_size])\n",
        "\n",
        "    #This block creates data loaders for training, validation and test datasets.\n",
        "    train_loader = DataLoader(train_dataset, self.batch_size_train, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, self.batch_size_test, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_set, self.batch_size_test, num_workers=4, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "  def cifar_100(self, root_path, split_ratio):\n",
        "    # This method loads Cifar-100 dataset\n",
        "    root = \"cifar_100\"\n",
        "    torch.manual_seed(self.seed)\n",
        "\n",
        "    # This downloads the training and test Cifar-100 datasets and also applies transformation  in the data.\n",
        "    train_set = datasets.CIFAR100(root=root_path, train=True, download=True, transform=self.transformations_train)\n",
        "    test_set = datasets.CIFAR100(root=root_path, train=False, download=True, transform=self.transformations_train)\n",
        "\n",
        "    classes_list = train_set.classes\n",
        "\n",
        "    # This line defines the size of validation dataset.\n",
        "    val_size = int(split_ratio*len(train_set))\n",
        "\n",
        "    # This line defines the size of training dataset.\n",
        "    train_size = int(len(train_set) - val_size)\n",
        "\n",
        "    #This line splits the training dataset into train and validation, according split ratio provided as input.\n",
        "    train_dataset, val_dataset = random_split(train_set, [train_size, val_size])\n",
        "\n",
        "    #This block creates data loaders for training, validation and test datasets.\n",
        "    train_loader = DataLoader(train_dataset, self.batch_size_train, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, self.batch_size_test, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_set, self.batch_size_test, num_workers=4, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "  \n",
        "  def get_indices(self, dataset, split_ratio):\n",
        "    nr_samples = len(dataset)\n",
        "    indices = list(range(nr_samples))\n",
        "    \n",
        "    train_size = nr_samples - int(np.floor(split_ratio * nr_samples))\n",
        "\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, test_idx = indices[:train_size], indices[train_size:]\n",
        "\n",
        "    return train_idx, test_idx\n",
        "\n",
        "  def caltech_256(self, root_path, split_ratio, savePath_idx):\n",
        "    # This method loads the Caltech-256 dataset.\n",
        "\n",
        "    torch.manual_seed(self.seed)\n",
        "    np.random.seed(seed=self.seed)\n",
        "\n",
        "    # This block receives the dataset path and applies the transformation data. \n",
        "    train_set = datasets.ImageFolder(root_path, transform=self.transformations_train)\n",
        "\n",
        "    val_set = datasets.ImageFolder(root_path, transform=self.transformations_test)\n",
        "    test_set = datasets.ImageFolder(root_path, transform=self.transformations_test)\n",
        "\n",
        "    if (os.path.exists(os.path.join(savePath_idx, \"training_idx_caltech256_id_%s.npy\"%(self.model_id)))):\n",
        "      \n",
        "      train_idx = np.load(os.path.join(savePath_idx, \"training_idx_caltech256_id_%s.npy\"%(self.model_id)))\n",
        "      val_idx = np.load(os.path.join(savePath_idx, \"validation_idx_caltech256_id_%s.npy\"%(self.model_id)))\n",
        "      test_idx = np.load(os.path.join(savePath_idx, \"test_idx_caltech256_id_%s.npy\"%(self.model_id)))\n",
        "\n",
        "    else:\n",
        "\n",
        "      # This line get the indices of the samples which belong to the training dataset and test dataset. \n",
        "      train_idx, test_idx = self.get_indices(train_set, split_ratio)\n",
        "\n",
        "      # This line mounts the training and test dataset, selecting the samples according indices. \n",
        "      train_data = torch.utils.data.Subset(train_set, indices=train_idx)\n",
        "      ##essa linha parecia estar faltando. copiei da versão anterior##\n",
        "\n",
        "      # This line gets the indices to split the train dataset into training dataset and validation dataset.\n",
        "      train_idx, val_idx = self.get_indices(train_data, split_ratio)\n",
        "\n",
        "      np.save(os.path.join(savePath_idx, \"traning_idx_caltech256_id_%s.npy\"%(self.model_id)), train_idx)\n",
        "      np.save(os.path.join(savePath_idx, \"validation_idx_caltech256_id_%s.npy\"%(self.model_id)), val_idx)\n",
        "      np.save(os.path.join(savePath_idx, \"test_idx_caltech256_id_%s.npy\"%(self.model_id)), test_idx)\n",
        "\n",
        "    # This line mounts the training and test dataset, selecting the samples according indices. \n",
        "    train_data = torch.utils.data.Subset(train_set, indices=train_idx)\n",
        "    val_data = torch.utils.data.Subset(val_set, indices=val_idx)\n",
        "    test_data = torch.utils.data.Subset(test_set, indices=test_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=self.batch_size_train, shuffle=True, num_workers=4)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=self.batch_size_test, num_workers=4)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=self.batch_size_test, num_workers=4)\n",
        "\n",
        "    return train_loader, val_loader, test_loader \n",
        "\n",
        "  def getDataset(self, root_path, dataset_name, split_ratio, savePath_idx):\n",
        "    self.dataset_name = dataset_name\n",
        "    def func_not_found():\n",
        "      print(\"No dataset %s is found\"%(self.dataset_name))\n",
        "\n",
        "    func_name = getattr(self, self.dataset_name, func_not_found)\n",
        "    train_loader, val_loader, test_loader = func_name(root_path, split_ratio, savePath_idx)\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egok2vU5Aqj5"
      },
      "source": [
        "def load_early_exit_dnn_model(model, model_path, device):\n",
        "  \n",
        "  model.load_state_dict(torch.load(model_path, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "  return model\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "  \"\"\"3x3 convolution with padding\"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  \"\"\"Basic Block defition.\n",
        "  Basic 3X3 convolution blocks for use on ResNets with layers <= 34.\n",
        "  Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "  \"\"\"\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = conv3x3(planes, planes)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(x)\n",
        "\n",
        "    out += identity\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class ConvBNActivation(nn.Sequential):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_planes: int,\n",
        "        out_planes: int,\n",
        "        kernel_size: int = 3,\n",
        "        stride: int = 1,\n",
        "        groups: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "        activation_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "        dilation: int = 1,\n",
        "    ) -> None:\n",
        "        padding = (kernel_size - 1) // 2 * dilation\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if activation_layer is None:\n",
        "            activation_layer = nn.ReLU6\n",
        "        super().__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, dilation=dilation, groups=groups,\n",
        "                      bias=False),\n",
        "            norm_layer(out_planes),\n",
        "            activation_layer(inplace=True)\n",
        "        )\n",
        "        self.out_channels = out_planes\n",
        "\n",
        "\n",
        "# necessary for backwards compatibility\n",
        "ConvBNReLU = ConvBNActivation\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        inp: int,\n",
        "        oup: int,\n",
        "        stride: int,\n",
        "        expand_ratio: int,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        hidden_dim = int(round(inp * expand_ratio))\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        layers: List[nn.Module] = []\n",
        "        if expand_ratio != 1:\n",
        "            # pw\n",
        "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1, norm_layer=norm_layer))\n",
        "        layers.extend([\n",
        "            # dw\n",
        "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, norm_layer=norm_layer),\n",
        "            # pw-linear\n",
        "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "            norm_layer(oup),\n",
        "        ])\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "        self.out_channels = oup\n",
        "        self._is_cn = stride > 1\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "class EarlyExitBlock(nn.Module):\n",
        "  \"\"\"\n",
        "  This EarlyExitBlock allows the model to terminate early when it is confident for classification.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape, n_classes, exit_type, device):\n",
        "    super(EarlyExitBlock, self).__init__()\n",
        "    self.input_shape = input_shape\n",
        "\n",
        "    _, channel, width, height = input_shape\n",
        "    self.expansion = width * height if exit_type == 'plain' else 1\n",
        "\n",
        "    self.layers = nn.ModuleList()\n",
        "\n",
        "    if (exit_type == 'bnpool'):\n",
        "      self.layers.append(nn.BatchNorm2d(channel))\n",
        "\n",
        "    if (exit_type != 'plain'):\n",
        "      self.layers.append(nn.AdaptiveAvgPool2d(1))\n",
        "    \n",
        "    #This line defines the data shape that fully-connected layer receives.\n",
        "    current_channel, current_width, current_height = self.get_current_data_shape()\n",
        "\n",
        "    self.layers = self.layers.to(device)\n",
        "\n",
        "    #This line builds the fully-connected layer\n",
        "    self.classifier = nn.Sequential(nn.Linear(current_channel*current_width*current_height, n_classes)).to(device)\n",
        "\n",
        "    self.softmax_layer = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "  def get_current_data_shape(self):\n",
        "    _, channel, width, height = self.input_shape\n",
        "    temp_layers = nn.Sequential(*self.layers)\n",
        "\n",
        "    input_tensor = torch.rand(1, channel, width, height)\n",
        "    _, output_channel, output_width, output_height = temp_layers(input_tensor).shape\n",
        "    return output_channel, output_width, output_height\n",
        "        \n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    output = self.classifier(x)\n",
        "    #confidence = self.softmax_layer()\n",
        "    return output\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "  \"\"\"1x1 convolution\"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class Early_Exit_DNN(nn.Module):\n",
        "  def __init__(self, model_name: str, n_classes: int, \n",
        "               pretrained: bool, n_branches: int, input_shape:tuple, \n",
        "               exit_type: str, device, distribution=\"linear\"):\n",
        "    super(Early_Exit_DNN, self).__init__()\n",
        "\n",
        "    \"\"\"\n",
        "    This classes builds an early-exit DNNs architectures\n",
        "    Args:\n",
        "\n",
        "    model_name: model name \n",
        "    n_classes: number of classes in a classification problem, according to the dataset\n",
        "    pretrained: \n",
        "    n_branches: number of branches (early exits) inserted into middle layers\n",
        "    input_shape: shape of the input image\n",
        "    exit_type: type of the exits\n",
        "    distribution: distribution method of the early exit blocks.\n",
        "    device: indicates if the model will processed in the cpu or in gpu\n",
        "    \n",
        "    Note: the term \"backbone model\" refers to a regular DNN model, considering no early exits.\n",
        "\n",
        "    \"\"\"\n",
        "    self.model_name = model_name\n",
        "    self.n_classes = n_classes\n",
        "    self.pretrained = pretrained\n",
        "    self.n_branches = n_branches\n",
        "    self.input_shape = input_shape\n",
        "    self.exit_type = exit_type\n",
        "    self.distribution = distribution\n",
        "    self.device = device\n",
        "    self.channel, self.width, self.height = input_shape\n",
        "\n",
        "\n",
        "    build_early_exit_dnn = self.select_dnn_architecture_model()\n",
        "\n",
        "    build_early_exit_dnn()\n",
        "\n",
        "  def select_dnn_architecture_model(self):\n",
        "    \"\"\"\n",
        "    This method selects the backbone to insert the early exits.\n",
        "    \"\"\"\n",
        "\n",
        "    architecture_dnn_model_dict = {\"alexnet\": self.early_exit_alexnet,\n",
        "                                   \"mobilenet\": self.early_exit_mobilenet,\n",
        "                                   \"resnet18\": self.early_exit_resnet18,\n",
        "                                   \"resnet34\": self.early_exit_resnet34}\n",
        "\n",
        "    return architecture_dnn_model_dict.get(self.model_name, self.invalid_model)\n",
        "\n",
        "  def select_distribution_method(self):\n",
        "    \"\"\"\n",
        "    This method selects the distribution method to insert early exits into the middle layers.\n",
        "    \"\"\"\n",
        "    distribution_method_dict = {\"linear\":self.linear_distribution,\n",
        "                                \"pareto\":self.paretto_distribution,\n",
        "                                \"fibonacci\":self.fibo_distribution}\n",
        "    return distribution_method_dict.get(self.distribution, self.invalid_distribution)\n",
        "    \n",
        "  def linear_distribution(self, i):\n",
        "    \"\"\"\n",
        "    This method defines the Flops to insert an early exits, according to a linear distribution.\n",
        "    \"\"\"\n",
        "    flop_margin = 1.0 / (self.n_branches+1)\n",
        "    return self.total_flops * flop_margin * (i+1)\n",
        "\n",
        "  def paretto_distribution(self, i):\n",
        "    \"\"\"\n",
        "    This method defines the Flops to insert an early exits, according to a pareto distribution.\n",
        "    \"\"\"\n",
        "    return self.total_flops * (1 - (0.8**(i+1)))\n",
        "\n",
        "  def fibo_distribution(self, i):\n",
        "    \"\"\"\n",
        "    This method defines the Flops to insert an early exits, according to a fibonacci distribution.\n",
        "    \"\"\"\n",
        "    gold_rate = 1.61803398875\n",
        "    return total_flops * (gold_rate**(i - self.num_ee))\n",
        "\n",
        "  def verifies_nr_exits(self, backbone_model):\n",
        "    \"\"\"\n",
        "    This method verifies if the number of early exits provided is greater than a number of layers in the backbone DNN model.\n",
        "    \"\"\"\n",
        "    \n",
        "    total_layers = len(list(backbone_model.children()))\n",
        "    if (self.n_branches >= total_layers):\n",
        "      raise Exception(\"The number of early exits is greater than number of layers in the DNN backbone model.\")\n",
        "\n",
        "  def countFlops(self, model):\n",
        "    \"\"\"\n",
        "    This method counts the numper of Flops in a given full DNN model or intermediate DNN model.\n",
        "    \"\"\"\n",
        "    input = torch.rand(1, self.channel, self.width, self.height)\n",
        "    flops, all_data = count_ops(model, input, print_readable=False, verbose=False)\n",
        "    return flops\n",
        "\n",
        "  def where_insert_early_exits(self):\n",
        "    \"\"\"\n",
        "    This method defines where insert the early exits, according to the dsitribution method selected.\n",
        "    Args:\n",
        "\n",
        "    total_flops: Flops of the backbone (full) DNN model.\n",
        "    \"\"\"\n",
        "    threshold_flop_list = []\n",
        "    distribution_method = self.select_distribution_method()\n",
        "\n",
        "    for i in range(self.n_branches):\n",
        "      threshold_flop_list.append(distribution_method(i))\n",
        "\n",
        "    return threshold_flop_list\n",
        "\n",
        "  def invalid_model(self):\n",
        "    raise Exception(\"This DNN model has not implemented yet.\")\n",
        "  def invalid_distribution(self):\n",
        "    raise Exception(\"This early-exit distribution has not implemented yet.\")\n",
        "\n",
        "  def is_suitable_for_exit(self):\n",
        "    \"\"\"\n",
        "    This method answers the following question. Is the position to place an early exit?\n",
        "    \"\"\"\n",
        "    intermediate_model = nn.Sequential(*(list(self.stages)+list(self.layers)))\n",
        "    current_flop = self.countFlops(intermediate_model)\n",
        "    return self.stage_id < self.n_branches and current_flop >= self.threshold_flop_list[self.stage_id]\n",
        "\n",
        "  def add_exit_block(self):\n",
        "    \"\"\"\n",
        "    This method adds an early exit in the suitable position.\n",
        "    \"\"\"\n",
        "    input_tensor = torch.rand(1, self.channel, self.width, self.height)\n",
        "\n",
        "    self.stages.append(nn.Sequential(*self.layers))\n",
        "\n",
        "    feature_shape = nn.Sequential(*self.stages)(input_tensor).shape\n",
        "\n",
        "    self.exits.append(EarlyExitBlock(feature_shape, self.n_classes, self.exit_type, self.device).to(self.device))\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.stage_id += 1    \n",
        "\n",
        "  def set_device(self):\n",
        "    \"\"\"\n",
        "    This method sets the device that will run the DNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    self.stages.to(self.device)\n",
        "    self.exits.to(self.device)\n",
        "    self.layers.to(self.device)\n",
        "    self.classifier.to(self.device)\n",
        "\n",
        "\n",
        "  def early_exit_alexnet(self):\n",
        "    \"\"\"\n",
        "    This method inserts early exits into a Alexnet model\n",
        "    \"\"\"\n",
        "\n",
        "    self.stages = nn.ModuleList()\n",
        "    self.exits = nn.ModuleList()\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.cost = []\n",
        "    self.stage_id = 0\n",
        "\n",
        "    # Loads the backbone model. In other words, Alexnet architecture provided by Pytorch.\n",
        "    backbone_model = models.alexnet(self.pretrained)\n",
        "\n",
        "    # It verifies if the number of early exits provided is greater than a number of layers in the backbone DNN model.\n",
        "    self.verifies_nr_exit_alexnet(backbone_model.features)\n",
        "    \n",
        "    # This obtains the flops total of the backbone model\n",
        "    self.total_flops = self.countFlops(backbone_model)\n",
        "\n",
        "    # This line obtains where inserting an early exit based on the Flops number and accordint to distribution method\n",
        "    self.threshold_flop_list = self.where_insert_early_exits()\n",
        "\n",
        "    for layer in backbone_model.features:\n",
        "      self.layers.append(layer)\n",
        "      if (isinstance(layer, nn.ReLU)) and (self.is_suitable_for_exit()):\n",
        "        self.add_exit_block()\n",
        "\n",
        "    \n",
        "    \n",
        "    self.layers.append(nn.AdaptiveAvgPool2d(output_size=(6, 6)))\n",
        "    self.stages.append(nn.Sequential(*self.layers))\n",
        "\n",
        "    \n",
        "    self.classifier = backbone_model.classifier\n",
        "    self.classifier[6] = nn.Linear(in_features=4096, out_features=self.n_classes, bias=True)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.set_device()\n",
        "\n",
        "  def verifies_nr_exit_alexnet(self, backbone_model):\n",
        "    \"\"\"\n",
        "    This method verifies if the number of early exits provided is greater than a number of layers in the backbone DNN model.\n",
        "    In AlexNet, we consider a convolutional block composed by: Convolutional layer, ReLU and he Max-pooling layer.\n",
        "    Hence, we consider that it makes no sense to insert side branches between these layers or only after the convolutional layer.\n",
        "    \"\"\"\n",
        "\n",
        "    count_relu_layer = 0\n",
        "    for layer in backbone_model:\n",
        "      if (isinstance(layer, nn.ReLU)):\n",
        "        count_relu_layer += 1\n",
        "\n",
        "    if (count_relu_layer > self.n_branches):\n",
        "      raise Exception(\"The number of early exits is greater than number of layers in the DNN backbone model.\")\n",
        "\n",
        "  def early_exit_resnet18(self):\n",
        "    \"\"\"\n",
        "    This method inserts early exits into a Resnet18 model\n",
        "    \"\"\"\n",
        "\n",
        "    self.stages = nn.ModuleList()\n",
        "    self.exits = nn.ModuleList()\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.cost = []\n",
        "    self.stage_id = 0\n",
        "\n",
        "    self.inplanes = 64\n",
        "\n",
        "    n_blocks = 4\n",
        "\n",
        "    backbone_model = models.resnet18(self.pretrained)\n",
        "\n",
        "    # It verifies if the number of early exits provided is greater than a number of layers in the backbone DNN model.\n",
        "    self.verifies_nr_exits(backbone_model)\n",
        "\n",
        "    # This obtains the flops total of the backbone model\n",
        "    self.total_flops = self.countFlops(backbone_model)\n",
        "\n",
        "    # This line obtains where inserting an early exit based on the Flops number and accordint to distribution method\n",
        "    self.threshold_flop_list = self.where_insert_early_exits()\n",
        "\n",
        "    building_first_layer = [\"conv1\", \"bn1\", \"relu\", \"maxpool\"]\n",
        "    for layer in building_first_layer:\n",
        "      self.layers.append(getattr(backbone_model, layer))\n",
        "\n",
        "    if (self.is_suitable_for_exit()):\n",
        "      self.add_exit_block()\n",
        "\n",
        "    for i in range(1, n_blocks+1):\n",
        "      \n",
        "      block_layer = getattr(backbone_model, \"layer%s\"%(i))\n",
        "\n",
        "      for l in block_layer:\n",
        "        self.layers.append(l)\n",
        "\n",
        "        if (self.is_suitable_for_exit()):\n",
        "          self.add_exit_block()\n",
        "    \n",
        "    self.layers.append(nn.AdaptiveAvgPool2d(1))\n",
        "    self.classifier = nn.Sequential(nn.Linear(512, self.n_classes))\n",
        "    self.stages.append(nn.Sequential(*self.layers))\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.set_device()\n",
        "\n",
        "  def early_exit_resnet34(self):\n",
        "    return True\n",
        "  \n",
        "\n",
        "  def early_exit_mobilenet(self):\n",
        "    \"\"\"\n",
        "    This method inserts early exits into a Mobilenet V2 model\n",
        "    \"\"\"\n",
        "\n",
        "    self.stages = nn.ModuleList()\n",
        "    self.exits = nn.ModuleList()\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.cost = []\n",
        "    self.stage_id = 0\n",
        "\n",
        "    last_channel = 1280\n",
        "    \n",
        "    # Loads the backbone model. In other words, Mobilenet architecture provided by Pytorch.\n",
        "    backbone_model = models.mobilenet_v2(self.pretrained)\n",
        "\n",
        "    # It verifies if the number of early exits provided is greater than a number of layers in the backbone DNN model.\n",
        "    self.verifies_nr_exits(backbone_model.features)\n",
        "    \n",
        "    # This obtains the flops total of the backbone model\n",
        "    self.total_flops = self.countFlops(backbone_model)\n",
        "\n",
        "    # This line obtains where inserting an early exit based on the Flops number and accordint to distribution method\n",
        "    self.threshold_flop_list = self.where_insert_early_exits()\n",
        "\n",
        "    for i, layer in enumerate(backbone_model.features.children()):\n",
        "      \n",
        "      self.layers.append(layer)    \n",
        "      if (self.is_suitable_for_exit()):\n",
        "        self.add_exit_block()\n",
        "\n",
        "    self.layers.append(nn.AdaptiveAvgPool2d(1))\n",
        "    self.stages.append(nn.Sequential(*self.layers))\n",
        "    \n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(last_channel, self.n_classes),)\n",
        "\n",
        "    self.set_device()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forwardTrain(self, x):\n",
        "    \"\"\"\n",
        "    This method is used to train the early-exit DNN model\n",
        "    \"\"\"\n",
        "    \n",
        "    output_list, conf_list, class_list  = [], [], []\n",
        "\n",
        "    for i, exitBlock in enumerate(self.exits):\n",
        "      \n",
        "      x = self.stages[i](x)\n",
        "      output_branch = exitBlock(x)\n",
        "      output_list.append(output_branch)\n",
        "\n",
        "      #Confidence is the maximum probability of belongs one of the predefined classes and inference_class is the argmax\n",
        "      conf, infered_class = torch.max(self.softmax(output_branch), 1)\n",
        "      conf_list.append(conf)\n",
        "      class_list.append(infered_class)\n",
        "\n",
        "    x = self.stages[-1](x)\n",
        "\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    output = self.classifier(x)\n",
        "    infered_conf, infered_class = torch.max(self.softmax(output), 1)\n",
        "    output_list.append(output)\n",
        "    conf_list.append(infered_conf)\n",
        "    class_list.append(infered_class)\n",
        "\n",
        "    return output_list, conf_list, class_list\n",
        "\n",
        "  def temperature_scale_overall(self, logits, temp_overall):\n",
        "    temperature = temp_overall.unsqueeze(1).expand(logits.size(0), logits.size(1)).to(self.device)\n",
        "    return logits / temperature\n",
        "\n",
        "  def temperature_scale_branches(self, logits, temp_branches, exit_branch):\n",
        "    temperature = temp_branches[exit_branch].unsqueeze(1).expand(logits.size(0), logits.size(1)).to(self.device)\n",
        "    return logits / temperature\n",
        "\n",
        "  def forward_inference_calib_overall(self, x, p_tar, temp_overall):\n",
        "    \"\"\"\n",
        "    This method is used to experiment of early-exit DNNs with overall calibration.\n",
        "    \"\"\"\n",
        "    output_list, conf_list, class_list  = [], [], []\n",
        "    n_exits = self.n_branches + 1\n",
        "    exit_branches = np.zeros(n_exits)\n",
        "    wasClassified = False\n",
        "\n",
        "    for i, exitBlock in enumerate(self.exits):\n",
        "      x = self.stages[i](x)\n",
        "      output_branch = exitBlock(x)\n",
        "      output_branch = self.temperature_scale_overall(output_branch, temp_overall)\n",
        "\n",
        "      conf_branch, infered_class_branch = torch.max(self.softmax(output_branch), 1)\n",
        "      conf_list.append(conf_branch.item()), class_list.append(infered_class_branch)\n",
        "\n",
        "      if (conf_branch.item() >= p_tar):\n",
        "        exit_branches[i] = 1\n",
        "\n",
        "        if (not wasClassified):\n",
        "          actual_exit_branch = i\n",
        "          actual_conf = conf_branch.item()\n",
        "          actual_inferred_class = infered_class_branch\n",
        "          wasClassified = True\n",
        "\n",
        "    x = self.stages[-1](x)\n",
        "    \n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    output = self.classifier(x)\n",
        "    output = self.temperature_scale_overall(output, temp_overall)\n",
        "\n",
        "    conf, infered_class = torch.max(self.softmax(output), 1)\n",
        "    conf_list.append(conf.item()), class_list.append(infered_class)\n",
        "\n",
        "    exit_branches[-1] = 1\n",
        "\n",
        "    if (conf.item() <  p_tar):\n",
        "      max_conf = np.argmax(conf_list)\n",
        "      conf_list[-1] = conf_list[max_conf]\n",
        "      class_list[-1] = class_list[max_conf]\n",
        "\n",
        "    if (not wasClassified):\n",
        "      actual_exit_branch = self.n_branches\n",
        "      actual_conf = conf_list[-1]\n",
        "      actual_inferred_class = class_list[-1]\n",
        "\n",
        "    return actual_conf, actual_inferred_class, actual_exit_branch, conf_list, class_list, exit_branches\n",
        "\n",
        "  def forward_inference_calib_branches(self, x, p_tar, temp_branches):\n",
        "    \"\"\"\n",
        "    This method is used to experiment of early-exit DNNs with calibration in all the branches.\n",
        "    \"\"\"\n",
        "\n",
        "    output_list, conf_list, class_list  = [], [], []\n",
        "    n_exits = self.n_branches + 1\n",
        "    exit_branches = np.zeros(n_exits)\n",
        "    wasClassified = False\n",
        "\n",
        "    for i, exitBlock in enumerate(self.exits):\n",
        "      x = self.stages[i](x)\n",
        "      output_branch = exitBlock(x)\n",
        "      output_branch = self.temperature_scale_branches(output_branch, temp_branches, i)\n",
        "\n",
        "      conf_branch, infered_class_branch = torch.max(self.softmax(output_branch), 1)\n",
        "      conf_list.append(conf_branch.item()), class_list.append(infered_class_branch)\n",
        "\n",
        "      if (conf_branch.item() >= p_tar):\n",
        "        exit_branches[i] = 1\n",
        "\n",
        "        if (not wasClassified):\n",
        "          actual_exit_branch = i\n",
        "          actual_conf = conf_branch.item()\n",
        "          actual_inferred_class = infered_class_branch\n",
        "          wasClassified = True\n",
        "\n",
        "    x = self.stages[-1](x)\n",
        "    \n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    output = self.classifier(x)\n",
        "    output = self.temperature_scale_branches(output, temp_branches, -1)\n",
        "    conf, infered_class = torch.max(self.softmax(output), 1)\n",
        "    conf_list.append(conf.item()), class_list.append(infered_class)\n",
        "\n",
        "    exit_branches[-1] = 1\n",
        "\n",
        "    if (conf.item() <  p_tar):\n",
        "      max_conf = np.argmax(conf_list)\n",
        "      conf_list[-1] = conf_list[max_conf]\n",
        "      class_list[-1] = class_list[max_conf]\n",
        "\n",
        "    if (not wasClassified):\n",
        "      actual_exit_branch = self.n_branches\n",
        "      actual_conf = conf_list[-1]\n",
        "      actual_inferred_class = class_list[-1]\n",
        "\n",
        "    return actual_conf, actual_inferred_class, actual_exit_branch, conf_list, class_list, exit_branches\n",
        "\n",
        "  def forward_inference_test(self, x, p_tar=0.5):\n",
        "    \"\"\"\n",
        "    This method is used to experiment of early-exit DNNs.\n",
        "    \"\"\"\n",
        "    output_list, conf_list, class_list  = [], [], []\n",
        "    n_exits = self.n_branches + 1\n",
        "    exit_branches = np.zeros(n_exits)\n",
        "    wasClassified = False\n",
        "\n",
        "    for i, exitBlock in enumerate(self.exits):\n",
        "      x = self.stages[i](x)\n",
        "\n",
        "      output_branch = exitBlock(x)\n",
        "      conf_branch, infered_class_branch = torch.max(self.softmax(output_branch), 1)\n",
        "      conf_list.append(conf_branch.item()), class_list.append(infered_class_branch)\n",
        "\n",
        "      if (conf_branch.item() >= p_tar):\n",
        "        exit_branches[i] = 1\n",
        "\n",
        "        if (not wasClassified):\n",
        "          actual_exit_branch = i\n",
        "          actual_conf = conf_branch.item()\n",
        "          actual_inferred_class = infered_class_branch\n",
        "          wasClassified = True\n",
        "\n",
        "    x = self.stages[-1](x)\n",
        "    \n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    output = self.classifier(x)\n",
        "    conf, infered_class = torch.max(self.softmax(output), 1)\n",
        "    conf_list.append(conf.item()), class_list.append(infered_class)\n",
        "\n",
        "    exit_branches[-1] = 1\n",
        "\n",
        "    if (conf.item() <  p_tar):\n",
        "      max_conf = np.argmax(conf_list)\n",
        "      conf_list[-1] = conf_list[max_conf]\n",
        "      class_list[-1] = class_list[max_conf]\n",
        "\n",
        "    if (not wasClassified):\n",
        "      actual_exit_branch = self.n_branches\n",
        "      actual_conf = conf_list[-1]\n",
        "      actual_inferred_class = class_list[-1]\n",
        "\n",
        "    return actual_conf, actual_inferred_class, actual_exit_branch, conf_list, class_list, exit_branches\n",
        "\n",
        "\n",
        "  def forwardEval(self, x, p_tar):\n",
        "    \"\"\"\n",
        "    This method is used to train the early-exit DNN model\n",
        "    \"\"\"\n",
        "    output_list, conf_list, class_list  = [], [], []\n",
        "\n",
        "    for i, exitBlock in enumerate(self.exits):\n",
        "      x = self.stages[i](x)\n",
        "\n",
        "      output_branch = exitBlock(x)\n",
        "      conf, infered_class = torch.max(self.softmax(output_branch), 1)\n",
        "\n",
        "      # Note that if confidence value is greater than a p_tar value, we terminate the dnn inference and returns the output\n",
        "      if (conf.item() >= p_tar):\n",
        "        return output_branch, conf.item(), infered_class, i\n",
        "\n",
        "      else:\n",
        "        output_list.append(output_branch)\n",
        "        conf_list.append(conf.item())\n",
        "        class_list.append(infered_class)\n",
        "\n",
        "    x = self.stages[-1](x)\n",
        "    \n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    output = self.classifier(x)\n",
        "    conf, infered_class = torch.max(self.softmax(output), 1)\n",
        "    \n",
        "    # Note that if confidence value is greater than a p_tar value, we terminate the dnn inference and returns the output\n",
        "    # This also happens in the last exit\n",
        "    if (conf.item() >= p_tar):\n",
        "      return output, conf.item(), infered_class, self.n_branches\n",
        "    else:\n",
        "\n",
        "      # If any exit can reach the p_tar value, the output is give by the more confidence output.\n",
        "      # If evaluation, it returns max(output), max(conf) and the number of the early exit.\n",
        "\n",
        "      conf_list.append(conf.item())\n",
        "      class_list.append(infered_class)\n",
        "      output_list.append(output)\n",
        "      max_conf = np.argmax(conf_list)\n",
        "      return output_list[max_conf], conf_list[max_conf], class_list[max_conf], self.n_branches\n",
        "\n",
        "\n",
        "  def forward(self, x, p_tar=0.5, training=True):\n",
        "    \"\"\"\n",
        "    This implementation supposes that, during training, this method can receive a batch containing multiple images.\n",
        "    However, during evaluation, this method supposes an only image.\n",
        "    \"\"\"\n",
        "    if (training):\n",
        "      return self.forwardTrain(x)\n",
        "    else:\n",
        "      return self.forwardEval(x, p_tar)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od2sihQKDsg8"
      },
      "source": [
        "class BranchesModelWithTemperature(nn.Module):\n",
        "  def __init__(self, model, n_branches, distortion_list, device, save_path, lr=0.01, max_iter=50):\n",
        "    super(BranchesModelWithTemperature, self).__init__()\n",
        "    \"\"\"\n",
        "    This method calibrates a early-exit DNN. The calibration goal is to turn the classification confidencer closer to the real model's accuracy.\n",
        "    In this work, we apply the calibration method called Temperature Scaling.\n",
        "    The paper below explains in detail: https://arxiv.org/pdf/1706.04599.pdf\n",
        "\n",
        "    Here, we follow two approaches:\n",
        "    * we find a temperature parameter for each side branch\n",
        "    * we find a temperature parameter for the entire early-exit DNN model.\n",
        "\n",
        "    \"\"\"\n",
        "    self.model = model            #this receives the architecture model. It is important to notice this models has already trained. \n",
        "    self.n_branches = n_branches  #the number of side branches or early exits.\n",
        "    self.n_exits = self.n_branches + 1 \n",
        "    self.device = device               \n",
        "    self.lr = lr                  # defines the learning rate of the calibration process.\n",
        "    self.max_iter = max_iter      #defines the number of iteractions to train the calibration process\n",
        "    self.save_path = save_path    # indicates the path to save the temperature in the temperature scaling method\n",
        "    \n",
        "    # This line initiates a parameters list of the temperature \n",
        "    self.temperature_branches = [nn.Parameter(torch.ones(1)*1.5) for i in range(self.n_exits)]\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "    # This line initiates a single temperature parameter for the entire early-exit DNN model\n",
        "    self.temperature_overall = nn.Parameter(torch.ones(1)*1.5)\n",
        "\n",
        "  def forward_branches(self, input, p_tar):\n",
        "    return self.model.forward_inference_calib_branches(input, p_tar, self.temperature_branches)\n",
        "\n",
        "  def forward_overall(self, input, p_tar):\n",
        "     return self.model.forward_inference_calib_overall(input, p_tar, self.temperature_overall)\n",
        "\n",
        "  def temperature_scale_overall(self, logits):\n",
        "    temperature = self.temperature_overall.unsqueeze(1).expand(logits.size(0), logits.size(1)).to(self.device)\n",
        "    return logits / temperature\n",
        "    \n",
        "  def temperature_scale_branches(self, logits, i):\n",
        "    temperature = self.temperature_branches[i].unsqueeze(1).expand(logits.size(0), logits.size(1)).to(self.device)\n",
        "    return logits / temperature\n",
        "  \n",
        "  def save_temperature_branches(self, p_tar, before_temperature_nll_list, after_temperature_nll_list):\n",
        "\n",
        "    temperature_dict = {}\n",
        "\n",
        "    df = pd.read_csv(self.save_path) if (os.path.exists(self.save_path)) else pd.DataFrame()\n",
        "    \n",
        "    for i in range(self.n_exits):\n",
        "      temperature_dict.update({\"p_tar\": p_tar, \"temperature_branch_%s\"%(i+1): (self.temperature_branches[i].data).cpu().numpy().item(),\n",
        "                               \"before_nll_branch_%s\"%(i+1): before_temperature_nll_list[i], \n",
        "                               \"after_nll_branch_%s\"%(i+1): after_temperature_nll_list[i]})\n",
        "    \n",
        "    df = df.append(pd.Series(temperature_dict), ignore_index=True)\n",
        "    df.to_csv(self.save_path)\n",
        "\n",
        "  def save_temperature_overall(self, p_tar, before_temperature_nll, after_temperature_nll):\n",
        "    \"\"\"\n",
        "    This method saves the temperature in an csv file in self.save_path\n",
        "    This saves: \n",
        "    p_tar: which means the threshold\n",
        "    before_temperature_nll: the error before the calibration  \n",
        "    after_temperature_nll: the error after the calibration\n",
        "    temperature parameter:\n",
        "                 \n",
        "    \"\"\"\n",
        "    temperature_dict = {}\n",
        "\n",
        "    df = pd.read_csv(self.save_path) if (os.path.exists(self.save_path)) else pd.DataFrame()\n",
        "    \n",
        "    temperature_dict.update({\"p_tar\": p_tar, \"temperature\": (self.temperature_overall.data).cpu().numpy().item(),\n",
        "                             \"before_nll\": before_temperature_nll, \"after_nll\": after_temperature_nll})\n",
        "    \n",
        "    df = df.append(pd.Series(temperature_dict), ignore_index=True)\n",
        "    df.to_csv(self.save_path)\n",
        "\n",
        "  def calibrate_overall(self, val_loader, p_tar):\n",
        "    \"\"\"\n",
        "    This method calibrates the entire model. In other words, this method finds a singles temperature parameter \n",
        "    for the entire early-exit DNN model\n",
        "    \"\"\"\n",
        "    nll_criterion = nn.CrossEntropyLoss().to(self.device)\n",
        "    \n",
        "    logits_list = []\n",
        "    labels_list = []\n",
        "    exit_branch_list = np.zeros(self.n_exits)\n",
        "\n",
        "    self.model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, (data, target) in enumerate(val_loader, 1):\n",
        "        if(i%1000==0):\n",
        "          print(\"Calibration Batch: %s/%s\"%(i, len(val_loader)))\n",
        "          \n",
        "        data, target = data.to(self.device), target.to(self.device)\n",
        "        \n",
        "        logits, conf, infer_class, exit_branch = self.model(data, p_tar, training=False)\n",
        "\n",
        "        logits_list.append(logits)\n",
        "        labels_list.append(target)\n",
        "        exit_branch_list[exit_branch] += 1\n",
        "\n",
        "    optimizer = optim.LBFGS([self.temperature_overall], lr=self.lr, max_iter=50)\n",
        "\n",
        "    logits_list = torch.cat(logits_list).to(self.device)\n",
        "    labels_list = torch.cat(labels_list).to(self.device)\n",
        "\n",
        "    before_temperature_nll = nll_criterion(logits_list, labels_list).item()\n",
        "\n",
        "    def eval():\n",
        "      loss = nll_criterion(self.temperature_scale_overall(logits_list), labels_list)\n",
        "      loss.backward()\n",
        "      return loss\n",
        "      \n",
        "    optimizer.step(eval)\n",
        "\n",
        "    after_temperature_nll = nll_criterion(self.temperature_scale_overall(logits_list), labels_list).item()\n",
        "    print(\"Before NLL: %s, After NLL: %s\"%(before_temperature_nll, after_temperature_nll))\n",
        "    print(\"Temp %s\"%(self.temperature_overall.item()))\n",
        "    # This saves the parameter to save the temperature parameter\n",
        "    self.save_temperature_overall(p_tar, before_temperature_nll, after_temperature_nll)\n",
        "\n",
        "\n",
        "  def calibrate_branches(self, val_loader, p_tar):\n",
        "    \"\"\"\n",
        "    This method calibrates for each side branch. In other words, this method finds a temperature parameter \n",
        "    for each side branch of the early-exit DNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    nll_criterion = nn.CrossEntropyLoss().to(self.device)\n",
        "    \n",
        "    logits_list = [[] for i in range(self.n_exits)]\n",
        "    labels_list = [[] for i in range(self.n_exits)]\n",
        "    before_temperature_nll_list, after_temperature_nll_list = [], []\n",
        "\n",
        "    self.model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, (data, target) in enumerate(val_loader, 1):\n",
        "        if(i%1000==0):\n",
        "          print(\"Calibration Batch: %s/%s\"%(i, len(val_loader)))\n",
        "          \n",
        "        data, target = data.to(self.device), target.to(self.device)\n",
        "        \n",
        "        logits, conf, infer_class, exit_branch = self.model(data, p_tar, training=False)\n",
        "\n",
        "        logits_list[exit_branch].append(logits)\n",
        "        labels_list[exit_branch].append(target)\n",
        "\n",
        "\n",
        "    for i in range(self.n_exits):\n",
        "      if (len(logits_list[i]) == 0):\n",
        "        continue\n",
        "      optimizer = optim.LBFGS([self.temperature_branches[i]], lr=self.lr, max_iter=50)\n",
        "\n",
        "      logit_branch = torch.cat(logits_list[i]).to(self.device)\n",
        "      label_branch = torch.cat(labels_list[i]).to(self.device)\n",
        "\n",
        "      before_temperature_nll = nll_criterion(logit_branch, label_branch).item()\n",
        "      before_temperature_nll_list.append(before_temperature_nll)\n",
        "\n",
        "      def eval(i):\n",
        "        loss = nll_criterion(self.temperature_scale_branches(logit_branch, i), label_branch)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "      \n",
        "      eval_branch = functools.partial(eval, i=i)\n",
        "      optimizer.step(eval_branch)\n",
        "\n",
        "      after_temperature_nll = nll_criterion(self.temperature_scale_branches(logit_branch, i), label_branch).item()\n",
        "      after_temperature_nll_list.append(after_temperature_nll)\n",
        "      print(\"Branch: %s, Before NLL: %s, After NLL: %s\"%(i+1, before_temperature_nll, after_temperature_nll))\n",
        "      print(\"Temp %s: %s\"%(i, self.temperature_branches[i].item()))\n",
        "    \n",
        "    # This saves the parameter to save the temperature parameter for each side branch\n",
        "    self.save_temperature_branches(p_tar, before_temperature_nll_list, after_temperature_nll_list)\n",
        "\n",
        "    return self"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkrDF72VBE1w"
      },
      "source": [
        "def experiement_early_exit_inference(model, test_loader, p_tar, n_branches, device, model_type):\n",
        "\n",
        "  n_exits = n_branches + 1\n",
        "  conf_list, infered_class_list, target_list, branch_exit_list  = [], [], [], []\n",
        "  conf_branches_list, infered_class_branches_list, exit_branches_list, isCorrect_list = [], [], [], []\n",
        "\n",
        "  nr_branch_exit, correct_branches = np.zeros(n_exits), np.zeros(n_exits)\n",
        "  correct_branches_samples = np.zeros((len(test_loader), n_exits))\n",
        "  nr_exit_branch =  np.zeros((len(test_loader), n_exits))\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, (data, target) in enumerate(test_loader, 1):\n",
        "      if (i % 1000 == 0):\n",
        "        print(\"Batch: %s\"%(i))\n",
        "      \n",
        "      data, target = data.to(device), target.float().to(device)\n",
        "\n",
        "      if (model_type == \"calib_overall\"):\n",
        "        conf, infered_class, branch_exit, conf_branches, infered_class_branches, exit_branches = model.forward_overall(data, p_tar)\n",
        "\n",
        "      elif (model_type == \"calib_branches\"):\n",
        "        conf, infered_class, branch_exit, conf_branches, infered_class_branches, exit_branches = model.forward_branches(data, p_tar)\n",
        "      \n",
        "      else:\n",
        "        conf, infered_class, branch_exit, conf_branches, infered_class_branches, exit_branches = model.forward_inference_test(data, p_tar)\n",
        "      \n",
        "      \n",
        "      conf_list.append(conf), infered_class_list.append(infered_class.item()), branch_exit_list.append(branch_exit)\n",
        "      target_list.append(target.item())\n",
        "      conf_branches_list.append(conf_branches), infered_class_branches_list.append(infered_class_branches), exit_branches_list.append(exit_branches)      \n",
        "      \n",
        "      nr_branch_exit[branch_exit] += 1\n",
        "      isCorrect = infered_class.eq(target.view_as(infered_class)).sum().item()\n",
        "      correct_branches[branch_exit] += isCorrect\n",
        "      isCorrect_list.append(isCorrect)\n",
        "      \n",
        "      correct_branches_samples[i-1, branch_exit] = isCorrect\n",
        "      nr_exit_branch[i-1, branch_exit] = 1\n",
        "\n",
        "      del data, target\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  result_samples = {\"p_tar\":len(target_list)*[p_tar], \n",
        "                    \"conf\":conf_list, \"infered_class\": infered_class_list,\n",
        "                    \"branch_exit\": branch_exit_list, \"target\": target_list,\n",
        "                    \"correct\": isCorrect_list}\n",
        "\n",
        "  conf_branches_list = np.array(conf_branches_list)\n",
        "  infered_class_branches_list = np.array(infered_class_branches_list)\n",
        "  exit_branches_list = np.array(exit_branches_list)\n",
        "\n",
        "  for i in range(n_exits):\n",
        "    result_samples.update({\"conf_branches_%s\"%(i+1): conf_branches_list[:, i],\n",
        "                           \"infered_class_branches_%s\"%(i+1): infered_class_branches_list[:, i],\n",
        "                           \"exit_branches_%s\"%(i+1): exit_branches_list[:, i],\n",
        "                           \"correct_branch_%s\"%(i+1): correct_branches_samples[:, i],\n",
        "                           \"nr_exit_branch_%s\"%(i+1): nr_exit_branch[:, i],\n",
        "                           \"nr_exit_edge_%s\"%(i+1): nr_exit_branch[:, :(i+1)].sum(axis=1)})\n",
        "\n",
        " \n",
        "\n",
        "  acc_branches = 100*(correct_branches/nr_branch_exit)\n",
        "  acc_avg = 100*(sum(correct_branches)/sum(nr_branch_exit))\n",
        "\n",
        "  nr_samples = sum(nr_branch_exit)\n",
        "  nr_total_samples = nr_samples\n",
        "\n",
        "  result = {\"p_tar\": p_tar, \"avg_acc\": acc_avg}\n",
        "\n",
        "  for i, (acc_branch, nr_branch) in enumerate(zip(acc_branches, nr_branch_exit), 1):\n",
        "    result.update({\"acc_branch_%s\"%(i): acc_branch})\n",
        "    result.update({\"nr_exit_branch_%s\"%(i): 100*(nr_branch/nr_samples)})\n",
        "    if (i < (n_branches+1) ):\n",
        "      result.update({\"edge_exit_rate_branch_%s\"%(i): 100*(sum(nr_branch_exit[:i])/sum(nr_branch_exit))})    \n",
        "    nr_samples -= nr_branch\n",
        "  \n",
        "  return result, result_samples\n",
        "\n",
        "\n",
        "def calibrating_early_exit_dnn(model, val_loader, p_tar, n_branches, device, savePathTemperature):\n",
        "\n",
        "  print(\"Calibrating ...\")\n",
        "\n",
        "  overall_calibrated_model = BranchesModelWithTemperature(model, n_branches, val_loader, device, savePathTemperature[\"calib_overall\"])\n",
        "  overall_calibrated_model.calibrate_overall(val_loader, p_tar)\n",
        "    \n",
        "  branches_calibrated_model = BranchesModelWithTemperature(model, n_branches, val_loader, device, savePathTemperature[\"calib_branches\"])\n",
        "  branches_calibrated_model.calibrate_branches(val_loader, p_tar)\n",
        "\n",
        "  return overall_calibrated_model, branches_calibrated_model \n",
        "\n",
        "def save_results_samples(result, save_path):\n",
        "  df_result = pd.read_csv(save_path) if (os.path.exists(save_path)) else pd.DataFrame()\n",
        "  df = pd.DataFrame(np.array(list(result.values())).T, columns=list(result.keys()))\n",
        "  df_result = df_result.append(df)\n",
        "  df_result.to_csv(save_path)\n",
        "\n",
        "def save_all_results_samples(no_calib_result, calib_overall_result, calib_branches_result, save_path_dict):\n",
        "    save_results_samples(no_calib_result, save_path_dict[\"no_calib\"])\n",
        "    save_results_samples(calib_overall_result, save_path_dict[\"calib_overall\"])\n",
        "    save_results_samples(calib_branches_result, save_path_dict[\"calib_branches\"])\n",
        "\n",
        "def save_results(result, save_path):\n",
        "  df_result = pd.read_csv(save_path) if (os.path.exists(save_path)) else pd.DataFrame()\n",
        "  df_result = df_result.append(pd.Series(result), ignore_index=True)\n",
        "  df_result.to_csv(save_path)\n",
        "\n",
        "\n",
        "def save_all_results(no_calib_result, calib_overall_result, calib_branches_result, save_path_dict):\n",
        "    save_results(no_calib_result, save_path_dict[\"no_calib\"])\n",
        "    save_results(calib_overall_result, save_path_dict[\"calib_overall\"])\n",
        "    save_results(calib_branches_result, save_path_dict[\"calib_branches\"])\n",
        "\n",
        "def exp_prob_edge_inference(model, test_loader, val_loader, threshold_list, n_branches, device, save_results_dict, \n",
        "                            save_results_samples_dict, save_temp_dict):\n",
        "\n",
        "  df_result = pd.DataFrame()\n",
        "  df_result_samples = pd.DataFrame()\n",
        "\n",
        "  for p_tar in threshold_list:\n",
        "    print(\"P_tar: %s\"%(p_tar))\n",
        "        \n",
        "    overall_calib_model, branches_calib_model = calibrating_early_exit_dnn(model, val_loader, p_tar, n_branches, device, save_temp_dict)\n",
        "\n",
        "    no_calib_result, no_calib_result_samples = experiement_early_exit_inference(model, test_loader, p_tar, n_branches, device, model_type=\"no_calib\")\n",
        "    \n",
        "    calib_overall_result, calib_overall_result_samples = experiement_early_exit_inference(overall_calib_model, test_loader, p_tar, \n",
        "                                                                                          n_branches, device, model_type=\"calib_overall\")\n",
        "    \n",
        "    calib_branches_result, calib_branches_result_samples = experiement_early_exit_inference(branches_calib_model, test_loader, p_tar, \n",
        "                                                                                            n_branches, device, model_type=\"calib_branches\")\n",
        "\n",
        "    save_all_results_samples(no_calib_result_samples, calib_overall_result_samples, calib_branches_result_samples, save_results_samples_dict)\n",
        "    save_all_results(no_calib_result, calib_overall_result, calib_branches_result, save_results_dict)\n",
        "    \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9asQ9ZiA32h",
        "outputId": "8acc3a98-8a97-4c94-8ba5-3840bd36a78c"
      },
      "source": [
        "model_name = \"mobilenet\"\n",
        "dataset_name = \"caltech256\"\n",
        "model_id = 1\n",
        "img_dim = 300\n",
        "input_dim = 300\n",
        "batch_size_train, batch_size_test = 64, 1\n",
        "split_ratio = 0.1\n",
        "save_idx = False\n",
        "\n",
        "\n",
        "root_dir = \"./drive/MyDrive/early_exit_test\" #diretório-raiz\n",
        "dataset_path = \"./drive/MyDrive/undistorted_datasets/Caltech256/256_ObjectCategories\" #caminho em que está salvo o dataset Caltec 256\n",
        "\n",
        "save_root_path = os.path.join(root_dir, dataset_name, model_name)\n",
        "if (not os.path.exists(save_root_path)):\n",
        "  os.makedirs(save_root_path)\n",
        "\n",
        "\n",
        "\n",
        "dataset = LoadDataset(img_dim, batch_size_train, batch_size_test, save_idx, model_id)\n",
        "_, val_loader, test_loader = dataset.caltech_256(dataset_path, split_ratio, save_root_path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738,
          "referenced_widgets": [
            "8b337975c22d46579a5437292bd555fb",
            "323977f630cd4fcf8f80a76014a52b93",
            "657740fc04744fa2a0ac2ea2615727ae",
            "a3b67458b23045c9ae0d31faff11db75",
            "364679377ef64df79bc9164ba5f11e52",
            "735167791ec24ad7a615e3777c9b78c5",
            "bc6957591b6b478dbdae70b41a312f10",
            "09fb1763e1f5443885896fcbabd48a61",
            "f29a754b0be2492090dd57e738bf754c",
            "74a16c448db24c0498db4aafb8a8c853",
            "850dc6e051ec41d8868b50ac6768baf1"
          ]
        },
        "id": "htXZZYKhBBv3",
        "outputId": "6fdfef07-6d47-4154-8bac-c2e42cb469a7"
      },
      "source": [
        "n_classes = 258\n",
        "pretrained = True\n",
        "n_branches = 5\n",
        "n_exits = n_branches + 1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "input_shape = (3, input_dim, input_dim)\n",
        "distribution = \"linear\"\n",
        "exit_type = \"bnpool\"\n",
        "\n",
        "# this line indicates the path to trained early-exit DNN model. You must change it to yours trained model\n",
        "model_path = \"./drive/MyDrive/project_quality_magazine/caltech256/mobilenet/models/pristine_model_mobilenet_caltech256_3_5_b.pth\"\n",
        "\n",
        "early_exit_model = Early_Exit_DNN(model_name, n_classes, pretrained, n_branches, input_shape, exit_type, device, distribution=distribution)\n",
        "early_exit_model = early_exit_model.to(device)\n",
        "early_exit_model.exits.to(device)\n",
        "\n",
        "# this line loads the trained model to the early_exit_model.\n",
        "early_exit_model = load_early_exit_dnn_model(early_exit_model, model_path, device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b337975c22d46579a5437292bd555fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Input size: (1, 3, 300, 300)\n",
            "589,580,360 FLOPs or approx. 0.59 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "20,880,000 FLOPs or approx. 0.02 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "41,040,000 FLOPs or approx. 0.04 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "99,090,000 FLOPs or approx. 0.10 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "149,040,000 FLOPs or approx. 0.15 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "179,133,664 FLOPs or approx. 0.18 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "200,666,592 FLOPs or approx. 0.20 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "222,199,520 FLOPs or approx. 0.22 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "236,870,560 FLOPs or approx. 0.24 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "256,508,960 FLOPs or approx. 0.26 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "276,147,360 FLOPs or approx. 0.28 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "295,785,760 FLOPs or approx. 0.30 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "319,837,024 FLOPs or approx. 0.32 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "362,602,528 FLOPs or approx. 0.36 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "405,368,032 FLOPs or approx. 0.41 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "435,627,360 FLOPs or approx. 0.44 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "467,659,360 FLOPs or approx. 0.47 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "499,691,360 FLOPs or approx. 0.50 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "547,083,360 FLOPs or approx. 0.55 GFLOPs\n",
            "Input size: (1, 3, 300, 300)\n",
            "588,299,360 FLOPs or approx. 0.59 GFLOPs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbudQQFDBHa6",
        "outputId": "9c36a91c-5377-40aa-969b-767bde1f8fb7"
      },
      "source": [
        "\n",
        "result_path = os.path.join(save_root_path, \"results\")\n",
        "temp_path = os.path.join(save_root_path, \"temperature\")\n",
        "\n",
        "if (not os.path.exists(result_path)):\n",
        "  os.makedirs(result_path)\n",
        "if (not os.path.exists(temp_path)):\n",
        "  os.makedirs(temp_path)\n",
        "\n",
        "\"\"\"\n",
        "No experimento, tem dois tipos de coletado dos resultados. Primeiramente, armazenamos os resultados de cada amostra. Ou seja,\n",
        "a cada inferência de uma imagem, extrai-se diversos resultados. Por exemplo, extrai-se se a inferência foi correta ou não, \n",
        "em qual ramo foi classificado, a confiança da classificação. Tudo isso é coletado.  \n",
        "Esses resultados são armazenados em arquivos .csv, cujos caminhos estão definidos no bloco abaixo. \n",
        "Definimos três arquivos para armazenar os resultados. \n",
        "save_no_calib_result_path: armazena os resultados do modelo sem calibração\n",
        "save_calib_overall_result_path: armazena os resultados do modelo com calibração que encontra um parâmetros temperature para o modelo inteiro\n",
        "save_calib_branches_result_path: armazena os resultados do modelo com calibração que encontra um parâmetro para cada ramo lateral. \n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Esse primeiro bloco define os caminhos para armazenar os resultados coletados de cada amostra\n",
        "\"\"\"\n",
        "save_no_calib_result_path =  os.path.join(result_path, \"exp_samples_no_calib_prob_edge_branches_%s_%s.csv\"%(n_branches, model_id)) \n",
        "save_calib_overall_result_path =  os.path.join(result_path, \"exp_samples_calib_overall_prob_edge_branches_%s_%s.csv\"%(n_branches, model_id)) \n",
        "save_calib_branches_result_path =  os.path.join(result_path, \"exp_samples_calib_branches_prob_edge_branches_%s_%s.csv\"%(n_branches, model_id)) \n",
        "\n",
        "\"\"\"\n",
        "Esse primeiro bloco define os caminhos para armazenar os resultados coletados depois avaliar o conjunto de teste. \n",
        "Por exemplo, nesses arquivos, serão armazenado resultados como acurácia do modelo, dos ramos laterais, o número total de amostras classificadas\n",
        "em cada ramo lateral. \n",
        "\"\"\"\n",
        "save_no_calib_path =  os.path.join(result_path, \"exp_no_calib_prob_edge_branches_%s_%s.csv\"%(n_branches, model_id)) \n",
        "save_calib_overall_path =  os.path.join(result_path, \"exp_calib_overall_prob_edge_branches_%s_%s.csv\"%(n_branches, model_id)) \n",
        "save_calib_branches_path =  os.path.join(result_path, \"exp_calib_branches_prob_edge_branches_%s_%s.csv\"%(n_branches, model_id)) \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Os dois próximos caminhos determinam onde salvar os parâmetros da calibração \n",
        "\"\"\"\n",
        "saveTemperatureBranchesPath = os.path.join(temp_path, \"branches_temp_scaling_branches_%s_%d.csv\"%(n_branches, model_id))\n",
        "saveTemperatureOverallPath = os.path.join(temp_path, \"branches_temp_scaling_overall_%s_%d.csv\"%(n_branches, model_id))\n",
        "\n",
        "save_results_samples_dict = {\"no_calib\": save_no_calib_result_path, \n",
        "                             \"calib_overall\": save_calib_overall_result_path, \n",
        "                             \"calib_branches\": save_calib_branches_result_path}\n",
        "\n",
        "save_results_dict = {\"no_calib\": save_no_calib_path, \n",
        "                     \"calib_overall\": save_calib_overall_path, \n",
        "                     \"calib_branches\": save_calib_branches_path}\n",
        "\n",
        "\n",
        "\n",
        "save_temp_dict = {\"calib_overall\":saveTemperatureOverallPath, \"calib_branches\": saveTemperatureBranchesPath}\n",
        "\n",
        "threshold_list = [0.7, 0.75, 0.8, 0.85, 0.9]\n",
        "\n",
        "exp_prob_edge_inference(early_exit_model, test_loader, val_loader, threshold_list, n_branches, device, save_results_dict, \n",
        "                        save_results_samples_dict, save_temp_dict)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P_tar: 0.7\n",
            "Calibrating ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Calibration Batch: 1000/2754\n",
            "Calibration Batch: 2000/2754\n",
            "Before NLL: 1.1887092590332031, After NLL: 1.205152153968811\n",
            "Temp 0.974169135093689\n",
            "Calibration Batch: 1000/2754\n",
            "Calibration Batch: 2000/2754\n",
            "Branch: 1, Before NLL: 3.897165060043335, After NLL: 3.237544298171997\n",
            "Temp 0: 1.6198656558990479\n",
            "Branch: 2, Before NLL: 1.8751262426376343, After NLL: 1.7494651079177856\n",
            "Temp 1: 1.2296142578125\n",
            "Branch: 3, Before NLL: 0.9309038519859314, After NLL: 0.9208670258522034\n",
            "Temp 2: 1.043660044670105\n",
            "Branch: 4, Before NLL: 0.7223101854324341, After NLL: 0.7164683938026428\n",
            "Temp 3: 1.0305297374725342\n",
            "Branch: 5, Before NLL: 0.840681791305542, After NLL: 0.7830145955085754\n",
            "Temp 4: 1.2107338905334473\n",
            "Branch: 6, Before NLL: 2.641573667526245, After NLL: 2.1959619522094727\n",
            "Temp 5: 1.7777109146118164\n",
            "Batch: 1000\n",
            "Batch: 2000\n",
            "Batch: 3000\n",
            "Batch: 1000\n",
            "Batch: 2000\n",
            "Batch: 3000\n",
            "Batch: 1000\n",
            "Batch: 2000\n",
            "Batch: 3000\n",
            "P_tar: 0.75\n",
            "Calibrating ...\n",
            "Calibration Batch: 1000/2754\n",
            "Calibration Batch: 2000/2754\n",
            "Before NLL: 1.1484795808792114, After NLL: 1.0624500513076782\n",
            "Temp 1.2624365091323853\n",
            "Calibration Batch: 1000/2754\n",
            "Calibration Batch: 2000/2754\n",
            "Branch: 1, Before NLL: 4.085559368133545, After NLL: 3.3177437782287598\n",
            "Temp 0: 1.672209620475769\n",
            "Branch: 2, Before NLL: 1.8784465789794922, After NLL: 1.7102714776992798\n",
            "Temp 1: 1.2843329906463623\n",
            "Branch: 3, Before NLL: 0.8290596008300781, After NLL: 0.8174355030059814\n",
            "Temp 2: 1.0518364906311035\n",
            "Branch: 4, Before NLL: 0.683396577835083, After NLL: 0.6732258200645447\n",
            "Temp 3: 1.0490490198135376\n",
            "Branch: 5, Before NLL: 0.7303225994110107, After NLL: 0.6779502034187317\n",
            "Temp 4: 1.2329058647155762\n",
            "Branch: 6, Before NLL: 2.5141727924346924, After NLL: 2.082653760910034\n",
            "Temp 5: 1.7784620523452759\n",
            "Batch: 1000\n",
            "Batch: 2000\n",
            "Batch: 3000\n",
            "Batch: 1000\n",
            "Batch: 2000\n",
            "Batch: 3000\n",
            "Batch: 1000\n",
            "Batch: 2000\n",
            "Batch: 3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "P_tar: 0.8\n",
            "Calibrating ...\n",
            "Calibration Batch: 1000/2754\n",
            "Calibration Batch: 2000/2754\n",
            "Before NLL: 1.0977435111999512, After NLL: 1.0025488138198853\n",
            "Temp 1.2886615991592407\n",
            "Calibration Batch: 1000/2754\n",
            "Calibration Batch: 2000/2754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-124ca0101858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m exp_prob_edge_inference(early_exit_model, test_loader, val_loader, threshold_list, n_branches, device, save_results_dict, \n\u001b[0;32m---> 36\u001b[0;31m                         save_results_samples_dict, save_temp_dict)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-eed1af2ebcf8>\u001b[0m in \u001b[0;36mexp_prob_edge_inference\u001b[0;34m(model, test_loader, val_loader, threshold_list, n_branches, device, save_results_dict, save_results_samples_dict, save_temp_dict)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"P_tar: %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_tar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0moverall_calib_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranches_calib_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibrating_early_exit_dnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_branches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_temp_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mno_calib_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_calib_result_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiement_early_exit_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_branches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"no_calib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-eed1af2ebcf8>\u001b[0m in \u001b[0;36mcalibrating_early_exit_dnn\u001b[0;34m(model, val_loader, p_tar, n_branches, device, savePathTemperature)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0mbranches_calibrated_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBranchesModelWithTemperature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_branches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavePathTemperature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"calib_branches\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m   \u001b[0mbranches_calibrated_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrate_branches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_tar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moverall_calibrated_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranches_calibrated_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d5b56133a781>\u001b[0m in \u001b[0;36mcalibrate_branches\u001b[0;34m(self, val_loader, p_tar)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calibration Batch: %s/%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbytes_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecvmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMSG_SPACE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}